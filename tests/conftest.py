"""Fixtures for pytest-based units.

Constants and helper functions can also be defined here. Doing so seems to
necessitate provision of an __init__.py file in this tests/ directory
such that Python considers it a package, but if that's already in place and
test execution is not deleteriously affected, then it should be no problem.

"""

import logging
import os
import shutil
import tempfile

from pandas.io.parsers import EmptyDataError
import pytest

from looper import setup_looper_logger
from looper.models import PipelineInterface, Project

__author__ = "Vince Reuter"
__email__ = "vreuter@virginia.edu"


setup_looper_logger()
_LOGGER = logging.getLogger(__name__)


PROJECT_CONFIG_LINES = """metadata:
  sample_annotation: samples.csv
  output_dir: test
  pipelines_dir: pipelines
  merge_table: merge.csv

derived_columns: [file, file2, dcol1, dcol2, nonmerged_col, nonmerged_col, data_source]

data_sources:
  src1: "tests/data/{sample_name}{col_modifier}.txt"
  src3: "tests/data/{sample_name}.txt"
  src2: "tests/data/{sample_name}-bamfile.bam"
""".splitlines(True)


PIPELINE_INTERFACE_CONFIG_LINES = """testpipeline.sh:
  name: test_pipeline  # Name used by pypiper so looper can find the logs
  looper_args: True
  arguments:
    "--input": file
  optional_arguments:
    "--sample-name": sample_name
    "--dcol1": dcol1
  required_input_files: [file, file2]
  resources:
    default:
      file_size: "0"
      cores: "8"
      mem: "32000"
      time: "2-00:00:00"
      partition: "longq"
testngs.sh:
  name: test_ngs_pipeline  # Name used by pypiper so looper can find the logs
  looper_args: True
  arguments:
    "--input": file
  optional_arguments:
    "--sample-name": sample_name
    "--genome": genome
    "--single-or-paired": read_type
    "--dcol1": dcol1
  required_input_files: [file]
  ngs_input_files: [file]
  resources:
    default:
      file_size: "0"
      cores: "8"
      mem: "32000"
      time: "2-00:00:00"
      partition: "longq"
""".splitlines(True)
_FILE_FILE2_BY_SAMPLE = [
        ["a.txt", "a.txt"],
        ["b.txt", "b.txt"],
        ["c.txt", "c.txt"],
        ["d-bamfile.bam", "d.txt"]
]
FILE_BY_SAMPLE = [[f] for f, _ in _FILE_FILE2_BY_SAMPLE]
PIPELINE_TO_REQD_INFILES_BY_SAMPLE = {
    "testpipeline.sh": _FILE_FILE2_BY_SAMPLE,
    "testngs.sh": FILE_BY_SAMPLE
}


SAMPLE_ANNOTATION_LINES = """sample_name,library,file,file2,organism,nonmerged_col,data_source,dcol2
a,testlib,src3,src3,,src3,src3,
b,testlib,,,,src3,src3,src1
c,testlib,src3,src3,,src3,src3,
d,testngs,src2,src3,human,,src3,
""".splitlines(True)
NUM_SAMPLES = len(SAMPLE_ANNOTATION_LINES) - 1
NGS_SAMPLE_INDICES = {3}


MERGE_TABLE_LINES = """sample_name,file,file2,dcol1,col_modifier
b,src1,src1,src1,1
b,src1,src1,src1,2
b,src1,src1,src1,3
""".splitlines(True)
# Only sample 'b' is merged, and it's in index-1 in the annotation lines.
MERGED_SAMPLE_INDICES = {1}
# In merge_table lines, file2 --> src1.
# In project config's data_sources section,
# src1 --> "tests/data/{sample_name}{col_modifier}.txt"
EXPECTED_MERGED_SAMPLE_FILEPATHS = {
    "file2": ["tests/data/b1.txt", "tests/data/b2.txt", "tests/data/b3.txt"]
}

# These are the derived_columns values specified in the merge_table header.
EXPECTED_MERGE_COLUMNS = ["file", "file2", "dcol1"]


_DATA_BY_TYPE = {
    Project: PROJECT_CONFIG_LINES,
    PipelineInterface: PIPELINE_INTERFACE_CONFIG_LINES
}
_ATTR_BY_TYPE = {
    Project: "project_config_file",
    PipelineInterface: "pipe_iface_config_file"
}


def _write_temp(lines, dirpath, fname):
    """
    Note that delete flag is a required argument since it's potentially
    dangerous. When writing to a directory path generated by pytest tmpdir
    fixture, the file will be deleted after the requesting class/function/etc.
    completes execution anyway, but otherwise failure to set the delete flag
    could leave lingering files. Perhaps that is desired and intended, but
    in general such responsibility should be delegated to the caller.

    :param collections.abc.Iterable(str) lines: sequence of
        lines to write to file
    :param str dirpath: path to directory in which to place the tempfile
    :param str fname: name for file in `dirpath` to which to write `lines`
    :return str: full path to written file
    """
    filepath = os.path.join(dirpath, fname)
    _LOGGER.debug("Writing %d lines to file '%s'", len(lines), filepath)
    with open(filepath, 'w') as tmpf:
        for l in lines:
            tmpf.write(l)
        return tmpf.name


@pytest.fixture(scope="class")
def write_project_files(request):
    """
    Write project config data to a temporary file system location.

    :param : path to temporary directory,
        provided by invocation of the builtin pytest fixture
    :return str: path to the temporary file with configuration data
    """
    dirpath = tempfile.mkdtemp()
    path_conf_file = _write_temp(PROJECT_CONFIG_LINES,
                                 dirpath=dirpath, fname="project_config.yaml")
    path_merge_table_file = _write_temp(
            MERGE_TABLE_LINES, dirpath=dirpath, fname="merge.csv")
    path_sample_annotation_file = _write_temp(
            SAMPLE_ANNOTATION_LINES, dirpath=dirpath, fname="samples.csv")
    request.cls.project_config_file = path_conf_file
    request.cls.merge_table_file = path_merge_table_file
    request.cls.sample_annotation_file = path_sample_annotation_file
    yield path_conf_file, path_merge_table_file, path_sample_annotation_file
    shutil.rmtree(dirpath)


@pytest.fixture(scope="class")
def pipe_iface_config_file(request):
    """
    Write pipeline interface config data to a temporary file system location.

    :param pytest._pytest.fixtures.SubRequest request: object requesting
        this fixture
    :return str: path to the temporary file with configuration data
    """
    dirpath = tempfile.mkdtemp()
    # TODO: determine name/subdir to which this needs to be written for recog.
    path_conf_file = _write_temp(
            PIPELINE_INTERFACE_CONFIG_LINES,
            dirpath=dirpath, fname="pipeline_interface.yaml"
    )
    request.cls.pipe_iface_config_file = path_conf_file
    yield path_conf_file
    shutil.rmtree(dirpath)


def _req_cls_att(req, attr):
    return getattr(getattr(req, "cls"), attr)


def _create(request, wanted):
    data_source = _req_cls_att(request, _ATTR_BY_TYPE[wanted])
    _LOGGER.debug("Using %s as source of data to build %s",
                  data_source, wanted.__class__.__name__)
    try:
        return wanted(data_source)
    except EmptyDataError:
        with open(data_source, 'r') as datafile:
            print("File contents:\n{}".format(datafile.readlines()))
        raise

    """

    data = _DATA_BY_TYPE[wanted]    # KeyError --> unexpected desired data type

    logging.info("Couldn't create %s via requestor's class's config file; "
                 "request may have come from an extra-class function; "
                 "will attempt creation by writing tempfile in %s.",
                 Project.__class__.__name, dirpath)

    return wanted(_write_temp(data, dirpath=dirpath,
                              suffix=".yaml", delete=False))
    """



@pytest.fixture(scope="function")
def proj(request):
    return _create(request, Project)


@pytest.fixture(scope="function")
def pipe_iface(request):
    return _create(request, PipelineInterface)
